# CogCache

[CogCache](https://touchcast.com/cogcache) is the most cost-effective way to access Azure OpenAI with no capacity limits.<br>
CogCache provides the highest performanceand lowest cost on the market for Azure OpenAI tokens, enabling you to unlock the full potential of generative AI:

- Up to 50% reduction in costs and carbon footprint
- Up to 100x faster response times, ensuring smooth and efficient operations
- Gain real-time insights, track performance key metrics and view all the logged requests for easy debugging
- View, control, refine and edit the output of generative AI applications via our Cognitive Caching technology
- Access the most advanced LLMs with no capacity limits
- Tokenized Pay-As-You-Go scheme

Additionally, CogCache leverages a cognitive caching mechanism to enhance the performance of AI-generated content. CogCache stores all LLM inputs and outputs in a cache and when similar or identical requests are made in the future, it can quickly retrieve the stored response instead of generating a new one each time, reducing the load on the AI model and speeding up the response time significantlyâ€”from the typical few seconds required to generate responses to milliseconds.

## Installation and Setup

First, you need to get the `API_KEY` from the [CogCache](https://app.cogcache.com/) website.

## Chat models

See a [usage example](/docs/integrations/chat/cogcache/).

```python
from langchain_community.chat_models import ChatCogCache
```
